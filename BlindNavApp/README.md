# 시각 장애인을 위한 음성 기반 길 안내 앱 (BlindNav)

## 📌 프로젝트 소개
이 프로젝트는 시각 장애인이 스마트폰 화면을 보지 않고도 목적지를 설정하고 길 안내를 받을 수 있도록 돕는 안드로이드 애플리케이션입니다. 
복잡한 터치 대신 **전체 화면 롱프레스(Long Press)** 제스처와 **음성 인식(STT)/음성 안내(TTS)**를 핵심 인터페이스로 사용합니다.

## ✨ 주요 기능

### 1. 직관적인 제스처 인터페이스
- **화면 어디든 길게 누르기 (Long Press):** 앱의 어느 화면에서든 화면을 길게 누르면 음성 인식이 시작됩니다. 정밀한 버튼 터치가 필요 없어 시각 장애인에게 최적화되어 있습니다.
- **햅틱 피드백 (Haptic Feedback):** 터치, 음성 인식 대기, 성공/실패 상태를 진동 패턴(틱, 더블 진동, 긴 진동)으로 사용자에게 물리적으로 전달합니다.

### 2. 게이미피케이션(Gamification) & 고대비 UI 디자인
- **테마 색상:** 각 모드별로 명확한 색상 코드를 부여하여 시각적 구분을 강화했습니다.
  - **메인(대기):** 🔵 Blue (안정적인 대기 상태)
  - **네비게이션:** 🟢 Green (긍정적인 진행 상태)
  - **보행 모드:** 🟣 Purple (주의가 필요한 활동 상태)
- **카드형 레이아웃:** 둥근 모서리와 굵은 테두리를 적용하여 각 정보 영역을 명확히 구분했습니다.

### 3. 음성 안내 시스템
- **TTS (Text-to-Speech):** 현재 상태, 목적지 정보, 남은 거리 등을 음성으로 안내합니다.
- **STT (Speech-to-Text):** "네비게이션", "보행", "메인" 등의 명령어를 음성으로 인식하여 화면을 전환합니다.

## 🛠 기술 스펙
- **Language:** Kotlin
- **Architecture:** MVVM (Model-View-ViewModel), Single Activity
- **Accessibility APIs:** 
  - `SpeechRecognizer`: 음성 명령 인식
  - `TextToSpeech`: 상황별 음성 안내
  - `Vibrator / VibratorManager`: 햅틱 피드백 구현

## 📱 화면 구성
1.  **메인 화면 (Main Screen):** 앱 실행 시 진입. 대기 상태.
2.  **네비게이션 화면 (Navigation Screen):** 목적지가 설정된 상태.
3.  **보행 화면 (Walking Screen):** 이동 중 안내 모드.

## 🚀 설치 및 실행 방법
1.  Android Studio에서 프로젝트를 엽니다.
2.  실제 안드로이드 기기 또는 에뮬레이터에 빌드합니다.
3.  앱 최초 실행 시 **마이크(Audio)** 및 **위치(Location)** 권한을 허용해야 정상 작동합니다.

---
*Developed for accessibility and inclusive design.*
